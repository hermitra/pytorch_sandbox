{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(777)  # set seed for reproducibility\n",
    "\n",
    "cuda0 = torch.device('cuda:0') # load GPU device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'data'...\n",
      "remote: Enumerating objects: 16, done.\u001b[K\n",
      "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
      "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
      "remote: Total 16 (delta 2), reused 16 (delta 2), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (16/16), 22.07 MiB | 41.39 MiB/s, done.\n",
      "Resolving deltas: 100% (2/2), done.\n"
     ]
    }
   ],
   "source": [
    "# prevent colab bug \n",
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "\n",
    "import torchvision\n",
    "\n",
    "# # setup for stable downloading MNIST dataset\n",
    "# from six.moves import urllib\n",
    "# opener = urllib.request.build_opener()\n",
    "# opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "# urllib.request.install_opener(opener)\n",
    "\n",
    "# # load MNIST dataset\n",
    "# mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True)\n",
    "\n",
    "# download MNIST data\n",
    "!rm -rf data\n",
    "!git clone https://github.com/knamdar/data\n",
    "\n",
    "# load MNIST dataset\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', download=False, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a digit 6:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+UlEQVR4nNWPoUtDYRTFTxC0CIJhQcS0l8aYGPSF8TBOhWX/gxXZUxSbQcOKzVWbJmGMLQ/TXDVtZbyhbGEWnwtazvEzCML7tq+teNLl/rjnngPMTV704mQ3b6w7UKotPq86LBvU2a7j0Cd16MwiFV1hrthcc7Gnz346uVn4m4rb5uHLAVfywPsQQHkdp7bp8qPRDnByHEnGfn1ADdLI1chJV52N5OERh5fw7jW+2wzUTcICeYFUg3F1MdOLq0nXcxJokwF88tp6WVENuZFCeJHCqSrGAN8m+7o0yH/YTXzSL8Wkxns2ArYmFEnaWX613xJ5Gwaz2P/QDwv6bXmT2FBqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the data\n",
    "image, label = mnist_train[13]\n",
    "print('This is a digit {}:'.format(label))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Convert images to tensors\n",
    "We want to convert this PIL.Image format to torch.Tensor using the `.ToTensor()` transform. Let's do it as follows for the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.MNIST(root='./data', download=False, train=True, transform=torchvision.transforms.ToTensor())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "image, label = mnist_train[13]\n",
    "print(type(image))\n",
    "print(image.shape) # torch.Size([1, 28, 28]) 1: channel (only brightness in this case), 28: height, 28: width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image has max=1.0 and min=0.0\n"
     ]
    }
   ],
   "source": [
    "print('This image has max={}'.format(image.max()), 'and min={}'.format(image.min()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Normalize the network inputs to be centered around 0\n",
    "We want to have our network inputs centered around 0. Right now there are between 0 and 1. We can use the `torchvision.transforms.Normalize` transform to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=(0.5,), std=(0.5,)),  # [0, 1] range => [-1, 1] range\n",
    "])\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', download=False, train=True,\n",
    "                                         transform=transform)\n",
    "mnist_val = torchvision.datasets.MNIST(root='./data', download=False, train=False,\n",
    "                                         transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "image, label = mnist_train[13]\n",
    "print(type(image))\n",
    "print(image.shape) # torch.Size([1, 28, 28]) 1: channel (only brightness in this case), 28: height, 28: width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image has max=1.0 and min=-1.0\n"
     ]
    }
   ],
   "source": [
    "print('This image has max={}'.format(image.max()), 'and min={}'.format(image.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size:\t60000\n",
      "validation set size:\t10000\n"
     ]
    }
   ],
   "source": [
    "print('training set size:\\t{}'.format(len(mnist_train)))\n",
    "print('validation set size:\\t{}'.format(len(mnist_val)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Load data as batches\n",
    "We want to automatically load the data as batches which we can do using the following function: `torch.utils.data.DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, \n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,                   # shuffle training set\n",
    "                                           num_workers=4,                  # turns on multi-processing loading so training is not blocked by data loading\n",
    "                                           pin_memory=True)                # pin_memory allows faster transfer from CPU to GPU\n",
    "val_loader = torch.utils.data.DataLoader(mnist_val, \n",
    "                                         batch_size=batch_size, \n",
    "                                         num_workers=4, \n",
    "                                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched image tensor shape: torch.Size([512, 1, 28, 28])\n",
      "batched label tensor shape: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# Each element yielded by `train_loader` (a Python iterable) is still a 2-tuple, \n",
    "# but now consisting of a batched image tensor, and a batched label tensor.\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "print('batched image tensor shape: {}'.format(images.shape)) # torch.Size([512, 1, 28, 28]) 512: batch size, 1: channel, 28: height, 28: width\n",
    "print('batched label tensor shape: {}'.format(labels.shape)) # torch.Size([512]) 512: batch size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do so based on LeNet as in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyNet()#.to(cuda0) # uncomment the .to(cuda0) if you want to run on GPU in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([123, 10])\n"
     ]
    }
   ],
   "source": [
    "random_input = torch.randn(123, 1, 28, 28)#, device=cuda0)\n",
    "output = net(random_input)\n",
    "print(output.shape) # torch.Size([123, 10]) 123: batch size, 10: number of classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define training and evaluating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, optim):\n",
    "    net.train()\n",
    "    for image_cpu, label_cpu in train_loader:\n",
    "        # put data onto GPU\n",
    "        image = image_cpu#.to(cuda0) # uncomment the .to(cuda0) if you want to run on GPU in Colab\n",
    "        label = label_cpu#.to(cuda0) # uncomment the .to(cuda0) if you want to run on GPU in Colab\n",
    "        \n",
    "        # clear gradient\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # forward through the network\n",
    "        output = net(image)\n",
    "        \n",
    "        # compute loss and gradient\n",
    "        loss = F.cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    net.eval()  # puts the network in eval mode. this is important when the \n",
    "                # network has layers that behaves differently in training and \n",
    "                # evaluation time, e.g., dropout and batch norm.\n",
    "    for image_cpu, label_cpu in val_loader:\n",
    "        # put data onto GPU\n",
    "        image = image_cpu#.to(cuda0) # uncomment the .to(cuda0) if you want to run on GPU in Colab\n",
    "        label = label_cpu#.to(cuda0) # uncomment the .to(cuda0) if you want to run on GPU in Colab\n",
    "        \n",
    "        with torch.no_grad():  # gradients are not tracked in this context manager\n",
    "                               # since we are evaluating, gradients are not needed \n",
    "                               # and we can save some time and GPU memory.\n",
    "              \n",
    "            # forward through the network, and get the predicted class\n",
    "            prediction = net(image).argmax(dim=-1)  \n",
    "            \n",
    "            total += image.size(0)  # batch size\n",
    "            correct += (prediction == label).sum().item()  # `.item()` retreives a python number from a 1-element tensor\n",
    "            \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At initialization, the network has accuracy 7.8200%\n"
     ]
    }
   ],
   "source": [
    "# Without any training, the network accuracy matches that of random guessing: ~10%.\n",
    "\n",
    "print('At initialization, the network has accuracy {:.4f}%'.format(evaluate(net) * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tValidation Accuracy: 7.8200%\n",
      "Epoch: 1\tValidation Accuracy: 75.0400%\n",
      "Epoch: 2\tValidation Accuracy: 91.4300%\n",
      "Epoch: 3\tValidation Accuracy: 96.0000%\n",
      "Epoch: 4\tValidation Accuracy: 96.1800%\n",
      "Epoch: 5\tValidation Accuracy: 94.7800%\n",
      "Epoch: 6\tValidation Accuracy: 95.0600%\n",
      "Epoch: 7\tValidation Accuracy: 96.6200%\n",
      "Epoch: 8\tValidation Accuracy: 94.7000%\n",
      "Epoch: 9\tValidation Accuracy: 98.4000%\n",
      "Done! \tValidation Accuracy: 97.5400%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "lr = 0.1\n",
    "\n",
    "optim = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch: {}\\tValidation Accuracy: {:.4f}%'.format(epoch, evaluate(net) * 100))\n",
    "    train(net, optim)\n",
    "\n",
    "print('Done! \\tValidation Accuracy: {:.4f}%'.format(evaluate(net) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "\n",
    "# Utility function\n",
    "def tensor2image(tensor):\n",
    "    return PIL.Image.fromarray((tensor.detach() * 127.5 + 128).clamp_(0, 255).to('cpu', torch.uint8).numpy()[0]) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a data sample we want to attack\n",
    "\n",
    "data, label = mnist_val[30]\n",
    "data = data.to(cuda0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the image\n",
    "\n",
    "tensor2image(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label is...\n",
    "\n",
    "print('label is', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what our trained network says about this image.\n",
    "\n",
    "\n",
    "# turn the network into eval mode\n",
    "net.eval()\n",
    "output = net(data.unsqueeze(0))  # .unsqueeze(0) insert a batch dimension so it looks like batched data\n",
    "prediction = output.argmax(-1)\n",
    "print('predicted class is', prediction.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
